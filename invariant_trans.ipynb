{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Config"
      ],
      "metadata": {
        "id": "EcSXKsaj1SUU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiwiCNWSz3mA"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from collections import Counter\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "CONFIG = {\n",
        "    \"data_path\": \"/content/algebra_train.jsonl\",\n",
        "    \"output_path\": \"graph_transformer_cot.pth\",\n",
        "    \"batch_size\": 16,\n",
        "    \"epochs\": 30,\n",
        "    \"d_model\": 128,\n",
        "    \"n_heads\": 8,\n",
        "    \"n_layers\": 4,\n",
        "    \"lr\": 3e-4\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloading and format from `algebra_train.jsonl`"
      ],
      "metadata": {
        "id": "HNdXrpnT1WlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def robust_parse_line(line):\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        return None\n",
        "\n",
        "\n",
        "    try:\n",
        "        parsed = json.loads(line)\n",
        "    except:\n",
        "        # fix format issues\n",
        "        line = re.sub(r\"'([^']*)':\", r'\"\\1\":', line)\n",
        "        line = re.sub(r',(\\s*[}\\]])', r'\\1', line)\n",
        "        line = re.sub(r'([{\\s,])(\\w+)(?=\\s*:)', r'\\1\"\\2\"', line)\n",
        "        try:\n",
        "            parsed = json.loads(line)\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    # tuples list dict handling\n",
        "    if isinstance(parsed, (list, tuple)):\n",
        "        return {\"correct_solution\": parsed, \"perturbations\": []}\n",
        "    elif isinstance(parsed, dict):\n",
        "        return parsed\n",
        "    return None\n",
        "\n",
        "def safe_extract_steps(data):\n",
        "    #steps from any structure\n",
        "\n",
        "    steps = []\n",
        "    if isinstance(data, (list, tuple)):\n",
        "        for item in data:\n",
        "            if isinstance(item, dict) and all(k in item for k in [\"st\", \"ot+1\", \"st+1\"]):\n",
        "                steps.append(item)\n",
        "    elif isinstance(data, dict):\n",
        "        if all(k in data for k in [\"st\", \"ot+1\", \"st+1\"]):\n",
        "            steps.append(data)\n",
        "    return steps\n",
        "\n",
        "def collect_all_texts(jsonl_path):\n",
        "    texts = []\n",
        "    skipped = 0\n",
        "\n",
        "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            ex = robust_parse_line(line)\n",
        "            if ex is None:\n",
        "                skipped += 1\n",
        "                continue\n",
        "\n",
        "            # extract correct_solution\n",
        "            correct_steps = safe_extract_steps(ex.get(\"correct_solution\", []))\n",
        "            for step in correct_steps:\n",
        "                texts.extend([step[\"st\"], step[\"ot+1\"], step[\"st+1\"]])\n",
        "\n",
        "            # extract perturbations\n",
        "            perturbations = ex.get(\"perturbations\", [])\n",
        "            if isinstance(perturbations, (list, tuple)):\n",
        "                for pert in perturbations:\n",
        "                    if isinstance(pert, dict):\n",
        "                        solution_steps = safe_extract_steps(pert.get(\"solution\", []))\n",
        "                        for step in solution_steps:\n",
        "\n",
        "                            texts.extend([step[\"st\"], step[\"ot+1\"], step[\"st+1\"]])\n",
        "\n",
        "    print(f\"collected {len(texts)} texts, skipped {skipped} lines\")\n",
        "    return texts"
      ],
      "metadata": {
        "id": "JxlHj2js1XAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization/padding + encoding\\"
      ],
      "metadata": {
        "id": "1vvI4h-n1aZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Vocab:\n",
        "    def __init__(self, min_freq=1):\n",
        "        self.min_freq = min_freq\n",
        "        self.token2id = {\"<pad>\": 0, \"<unk>\": 1}\n",
        "        self.id2token = {0: \"<pad>\", 1: \"<unk>\"}\n",
        "\n",
        "    def build(self, texts):\n",
        "        counter = Counter()\n",
        "        for t in texts:\n",
        "            counter.update(str(t).split())\n",
        "        for tok, freq in counter.items():\n",
        "            if freq >= self.min_freq and tok not in self.token2id:\n",
        "                idx = len(self.token2id)\n",
        "                self.token2id[tok] = idx\n",
        "                self.id2token[idx] = tok\n",
        "\n",
        "    def encode(self, text, max_len):\n",
        "        toks = str(text).split()\n",
        "        ids = [self.token2id.get(t, 1) for t in toks][:max_len]\n",
        "        if len(ids) < max_len:\n",
        "            ids += [0] * (max_len - len(ids))\n",
        "        return ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token2id)\n",
        "\n",
        "class CoTGraphDataset(Dataset):\n",
        "    def __init__(self, jsonl_path, vocab, max_state_len=32, max_steps=8):\n",
        "        self.vocab = vocab\n",
        "        self.max_state_len = max_state_len\n",
        "        self.max_steps = max_steps\n",
        "        self.examples = []\n",
        "        skipped = 0\n",
        "\n",
        "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line_num, line in enumerate(f, 1):\n",
        "                ex = robust_parse_line(line)\n",
        "                if ex is None:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    self._add_example(ex)\n",
        "                except:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "\n",
        "        print(f\"dataset: {len(self.examples)} graphs, skipped {skipped} lines\")\n",
        "\n",
        "    def _add_example(self, ex):\n",
        "\n",
        "        # correct_solution\n",
        "        correct_steps = safe_extract_steps(ex.get(\"correct_solution\", []))\n",
        "        if correct_steps:\n",
        "            self._add_solution_graph(correct_steps, label=0)\n",
        "\n",
        "        # perturbations\n",
        "\n",
        "        perturbations = ex.get(\"perturbations\", [])\n",
        "        if isinstance(perturbations, (list, tuple)):\n",
        "            for pert in perturbations:\n",
        "                if isinstance(pert, dict):\n",
        "                    solution_steps = safe_extract_steps(pert.get(\"solution\", []))\n",
        "                    if solution_steps:\n",
        "                        self._add_solution_graph(solution_steps, label=1)\n",
        "\n",
        "    def _add_solution_graph(self, solution_steps, label):\n",
        "        steps = solution_steps[:self.max_steps]\n",
        "        if not steps:\n",
        "            return\n",
        "\n",
        "        node_to_id = {}\n",
        "        node_strings = []\n",
        "        node_types = []\n",
        "\n",
        "        def get_node_id(text, node_type):\n",
        "            text = str(text)\n",
        "            if text not in node_to_id:\n",
        "                node_id = len(node_strings)\n",
        "                node_to_id[text] = node_id\n",
        "                node_strings.append(text)\n",
        "                node_types.append(node_type)\n",
        "            return node_to_id[text]\n",
        "\n",
        "        edges = []\n",
        "        for step in steps:\n",
        "            if isinstance(step, dict) and all(k in step for k in [\"st\", \"ot+1\", \"st+1\"]):\n",
        "                st_id = get_node_id(step[\"st\"], 0)\n",
        "                op_id = get_node_id(step[\"ot+1\"], 1)\n",
        "                st1_id = get_node_id(step[\"st+1\"], 0)\n",
        "                edges.extend([(st_id, op_id), (op_id, st1_id)])\n",
        "\n",
        "        if edges:\n",
        "            self.examples.append({\n",
        "                \"node_strings\": node_strings,\n",
        "                \"node_types\": node_types,\n",
        "                \"edges\": edges,\n",
        "                \"label\": label\n",
        "            })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.examples[idx]\n",
        "        node_token_ids = torch.tensor([self.vocab.encode(s, self.max_state_len)\n",
        "                                     for s in ex[\"node_strings\"]], dtype=torch.long)\n",
        "        edge_index = torch.tensor(ex[\"edges\"], dtype=torch.long).t() if ex[\"edges\"] else torch.empty((2, 0), dtype=torch.long)\n",
        "        node_type_ids = torch.tensor(ex[\"node_types\"], dtype=torch.long)\n",
        "        return {\n",
        "            \"node_token_ids\": node_token_ids,\n",
        "            \"edge_index\": edge_index,\n",
        "            \"node_type_ids\": node_type_ids,\n",
        "            \"label\": torch.tensor(ex[\"label\"], dtype=torch.float32)\n",
        "        }\n",
        "\n",
        "def collate_graphs(batch):\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "ozWqf_cW1cbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Transformer"
      ],
      "metadata": {
        "id": "aTgh0MXK1eRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphTransformerCoT(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=128, n_heads=8, n_layers=4):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        #token embedding - semantic\n",
        "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
        "        #positioning of each token\n",
        "        self.pos_embed = nn.Parameter(torch.randn(32, d_model) * 0.02)\n",
        "        self.node_type_embed = nn.Embedding(2, d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=n_heads, dim_feedforward=512,\n",
        "            dropout=0.15, activation=\"gelu\", batch_first=True, norm_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        self.graph_pool = nn.Sequential(\n",
        "            nn.Linear(d_model * 2, d_model),\n",
        "            nn.GELU(), nn.Dropout(0.2),\n",
        "            nn.Linear(d_model, 1)\n",
        "        )\n",
        "\n",
        "    def forward_single(self, node_token_ids, node_type_ids, edge_index):\n",
        "        device = node_token_ids.device\n",
        "        N, L = node_token_ids.shape\n",
        "        #each node's token sequence is collapsed into a single vector by averaging --> make each node = one vector representing one step\n",
        "\n",
        "        token_emb = self.token_embed(node_token_ids) + self.pos_embed[:L, :].unsqueeze(0)\n",
        "        node_emb = token_emb.mean(dim=1)\n",
        "\n",
        "        #node type injection - understand that it IS a step, not raw text\n",
        "        node_emb = node_emb + self.node_type_embed(node_type_ids)\n",
        "        h = self.transformer(node_emb.unsqueeze(0)).squeeze(0)\n",
        "\n",
        "\n",
        " # transformer operates over nodes --> attend to every other node / learn patterns + contradictions\n",
        "        if edge_index.numel() > 0:\n",
        "\n",
        "          #for every edge --> src --> tgt --> multiply their embeddings + average across all edges / if no edges, just zero vector ( understand if all steps AGREE with each other)\n",
        "            src, tgt = edge_index\n",
        "            edge_context = (h[src] * h[tgt]).mean(dim=0)\n",
        "        else:\n",
        "            edge_context = torch.zeros_like(h.mean(dim=0), device=device)\n",
        "\n",
        "            #whole-graph representation\n",
        "        global_emb = h.mean(dim=0)\n",
        "\n",
        "      #final decision head (concatenate local relational edges and global reasoning nodes)\n",
        "        final_emb = torch.cat([edge_context, global_emb], dim=-1)\n",
        "        return self.graph_pool(final_emb).squeeze(-1)\n",
        "\n",
        "    def forward(self, batch):\n",
        "\n",
        "      #each example is separately + output a vector of scores\n",
        "        device = next(self.parameters()).device\n",
        "        return torch.stack([\n",
        "            self.forward_single(\n",
        "                ex[\"node_token_ids\"].to(device),\n",
        "                ex[\"node_type_ids\"].to(device),\n",
        "                ex[\"edge_index\"].to(device)\n",
        "            ) for ex in batch\n",
        "        ])\n",
        "\n",
        "\n",
        "        # overall this views the structure and logic of invariants, not guessing the answer\n"
      ],
      "metadata": {
        "id": "nQZj9jNl1fm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [Run + train + val]"
      ],
      "metadata": {
        "id": "kWkQBFGD1jBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    print(\"vocab load\")\n",
        "    texts = collect_all_texts(CONFIG[\"data_path\"])\n",
        "    if not texts:\n",
        "        print(\"no valid text\")\n",
        "        return\n",
        "\n",
        "    vocab = Vocab(min_freq=2)\n",
        "    vocab.build(texts)\n",
        "    print(f\"vocab size: {len(vocab)}\")\n",
        "\n",
        "    print(\"load dataset\")\n",
        "    dataset = CoTGraphDataset(CONFIG[\"data_path\"], vocab)\n",
        "\n",
        "    if len(dataset) == 0:\n",
        "        print(\"no valid graphs\")\n",
        "        return\n",
        "\n",
        "    train_size = int(0.9 * len(dataset))\n",
        "    train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=CONFIG[\"batch_size\"], shuffle=True,\n",
        "                             collate_fn=collate_graphs, num_workers=0)\n",
        "    val_loader = DataLoader(val_ds, batch_size=CONFIG[\"batch_size\"], shuffle=False,\n",
        "                           collate_fn=collate_graphs, num_workers=0)\n",
        "\n",
        "    print(f\"train: {len(train_ds)}, val: {len(val_ds)}\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\" device: {device}\")\n",
        "\n",
        "    model = GraphTransformerCoT(\n",
        "        vocab_size=len(vocab), d_model=CONFIG[\"d_model\"],\n",
        "        n_heads=CONFIG[\"n_heads\"], n_layers=CONFIG[\"n_layers\"]\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=CONFIG[\"lr\"], weight_decay=0.01)\n",
        "    scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG[\"epochs\"])\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    print(\"training...\")\n",
        "\n",
        "    for epoch in range(CONFIG[\"epochs\"]):\n",
        "        model.train()\n",
        "        train_correct, train_total = 0, 0\n",
        "        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "\n",
        "        for batch in train_pbar:\n",
        "            logits = model(batch)\n",
        "            labels = torch.stack([ex[\"label\"] for ex in batch]).to(device)\n",
        "            loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = (logits.sigmoid() > 0.5).long()\n",
        "            train_correct += (preds == labels.long()).sum().item()\n",
        "            train_total += len(batch)\n",
        "\n",
        "            train_pbar.set_postfix(acc=f\"{train_correct/train_total:.3f}\")\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_correct, val_total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                logits = model(batch)\n",
        "                labels = torch.stack([ex[\"label\"] for ex in batch]).to(device)\n",
        "                preds = (logits.sigmoid() > 0.5).long()\n",
        "                val_correct += (preds == labels.long()).sum().item()\n",
        "                val_total += len(batch)\n",
        "\n",
        "        train_acc = train_correct / train_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f\"epoch {epoch+1}: train {train_acc:.3f}, validation {val_acc:.3f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"vocab\": vocab.token2id,\n",
        "                \"val_acc\": val_acc,\n",
        "                \"epoch\": epoch\n",
        "            }, CONFIG[\"output_path\"])\n",
        "            print(f\"model saved: {val_acc:.3f}\")\n",
        "\n",
        "    print(f\"---- DONE ---- best val acc: {best_val_acc:.3f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "j8pEEoOo1kte"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}